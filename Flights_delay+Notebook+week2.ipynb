{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines=pd.read_csv('./airlines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>AIRLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UA</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>American Airlines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>US Airways Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F9</td>\n",
       "      <td>Frontier Airlines Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B6</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IATA_CODE                 AIRLINE\n",
       "0        UA   United Air Lines Inc.\n",
       "1        AA  American Airlines Inc.\n",
       "2        US         US Airways Inc.\n",
       "3        F9  Frontier Airlines Inc.\n",
       "4        B6         JetBlue Airways"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airports=pd.read_csv('./airports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>AIRPORT</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABE</td>\n",
       "      <td>Lehigh Valley International Airport</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>PA</td>\n",
       "      <td>USA</td>\n",
       "      <td>40.65236</td>\n",
       "      <td>-75.44040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>Abilene Regional Airport</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>32.41132</td>\n",
       "      <td>-99.68190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABQ</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>NM</td>\n",
       "      <td>USA</td>\n",
       "      <td>35.04022</td>\n",
       "      <td>-106.60919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABR</td>\n",
       "      <td>Aberdeen Regional Airport</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "      <td>USA</td>\n",
       "      <td>45.44906</td>\n",
       "      <td>-98.42183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABY</td>\n",
       "      <td>Southwest Georgia Regional Airport</td>\n",
       "      <td>Albany</td>\n",
       "      <td>GA</td>\n",
       "      <td>USA</td>\n",
       "      <td>31.53552</td>\n",
       "      <td>-84.19447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IATA_CODE                              AIRPORT         CITY STATE COUNTRY  \\\n",
       "0       ABE  Lehigh Valley International Airport    Allentown    PA     USA   \n",
       "1       ABI             Abilene Regional Airport      Abilene    TX     USA   \n",
       "2       ABQ    Albuquerque International Sunport  Albuquerque    NM     USA   \n",
       "3       ABR            Aberdeen Regional Airport     Aberdeen    SD     USA   \n",
       "4       ABY   Southwest Georgia Regional Airport       Albany    GA     USA   \n",
       "\n",
       "   LATITUDE  LONGITUDE  \n",
       "0  40.65236  -75.44040  \n",
       "1  32.41132  -99.68190  \n",
       "2  35.04022 -106.60919  \n",
       "3  45.44906  -98.42183  \n",
       "4  31.53552  -84.19447  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "flights=pd.read_csv('./flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>98</td>\n",
       "      <td>N407AS</td>\n",
       "      <td>ANC</td>\n",
       "      <td>SEA</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>408.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>2336</td>\n",
       "      <td>N3KUAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>PBI</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>741.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>840</td>\n",
       "      <td>N171US</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CLT</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>811.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AA</td>\n",
       "      <td>258</td>\n",
       "      <td>N3HYAA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>756.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>AS</td>\n",
       "      <td>135</td>\n",
       "      <td>N527AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>ANC</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>259.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "0  2015      1    1            4      AS             98      N407AS   \n",
       "1  2015      1    1            4      AA           2336      N3KUAA   \n",
       "2  2015      1    1            4      US            840      N171US   \n",
       "3  2015      1    1            4      AA            258      N3HYAA   \n",
       "4  2015      1    1            4      AS            135      N527AS   \n",
       "\n",
       "  ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE      ...        \\\n",
       "0            ANC                 SEA                    5      ...         \n",
       "1            LAX                 PBI                   10      ...         \n",
       "2            SFO                 CLT                   20      ...         \n",
       "3            LAX                 MIA                   20      ...         \n",
       "4            SEA                 ANC                   25      ...         \n",
       "\n",
       "   ARRIVAL_TIME  ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  \\\n",
       "0         408.0          -22.0         0          0                  NaN   \n",
       "1         741.0           -9.0         0          0                  NaN   \n",
       "2         811.0            5.0         0          0                  NaN   \n",
       "3         756.0           -9.0         0          0                  NaN   \n",
       "4         259.0          -21.0         0          0                  NaN   \n",
       "\n",
       "   AIR_SYSTEM_DELAY  SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  \\\n",
       "0               NaN             NaN            NaN                  NaN   \n",
       "1               NaN             NaN            NaN                  NaN   \n",
       "2               NaN             NaN            NaN                  NaN   \n",
       "3               NaN             NaN            NaN                  NaN   \n",
       "4               NaN             NaN            NaN                  NaN   \n",
       "\n",
       "   WEATHER_DELAY  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ORIGIN_AIRPORT', 'DEPARTURE_DELAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_flights_df = flights[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airports_name = airports[['IATA_CODE', 'AIRPORT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_flights_df = small_flights_df.merge(airports_name, how='left' , left_on='ORIGIN_AIRPORT' , right_on='IATA_CODE' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>IATA_CODE</th>\n",
       "      <th>AIRPORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANC</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAX</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SFO</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAX</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEA</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle-Tacoma International Airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN_AIRPORT  DEPARTURE_DELAY IATA_CODE  \\\n",
       "0            ANC            -11.0       ANC   \n",
       "1            LAX             -8.0       LAX   \n",
       "2            SFO             -2.0       SFO   \n",
       "3            LAX             -5.0       LAX   \n",
       "4            SEA             -1.0       SEA   \n",
       "\n",
       "                                       AIRPORT  \n",
       "0  Ted Stevens Anchorage International Airport  \n",
       "1            Los Angeles International Airport  \n",
       "2          San Francisco International Airport  \n",
       "3            Los Angeles International Airport  \n",
       "4         Seattle-Tacoma International Airport  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "small_flights_df = small_flights_df[['ORIGIN_AIRPORT', 'DEPARTURE_DELAY', 'AIRPORT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>AIRPORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANC</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAX</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SFO</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>San Francisco International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAX</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEA</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Seattle-Tacoma International Airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN_AIRPORT  DEPARTURE_DELAY                                      AIRPORT\n",
       "0            ANC            -11.0  Ted Stevens Anchorage International Airport\n",
       "1            LAX             -8.0            Los Angeles International Airport\n",
       "2            SFO             -2.0          San Francisco International Airport\n",
       "3            LAX             -5.0            Los Angeles International Airport\n",
       "4            SEA             -1.0         Seattle-Tacoma International Airport"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_flights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANC_delays = small_flights_df[small_flights_df.ORIGIN_AIRPORT == 'ANC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DEPARTURE_DELAY</th>\n",
       "      <th>AIRPORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANC</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANC</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ANC</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ANC</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ANC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ted Stevens Anchorage International Airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ORIGIN_AIRPORT  DEPARTURE_DELAY  \\\n",
       "0             ANC            -11.0   \n",
       "15            ANC             -4.0   \n",
       "16            ANC            -14.0   \n",
       "18            ANC             -4.0   \n",
       "32            ANC              NaN   \n",
       "\n",
       "                                        AIRPORT  \n",
       "0   Ted Stevens Anchorage International Airport  \n",
       "15  Ted Stevens Anchorage International Airport  \n",
       "16  Ted Stevens Anchorage International Airport  \n",
       "18  Ted Stevens Anchorage International Airport  \n",
       "32  Ted Stevens Anchorage International Airport  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANC_delays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_airports = list(set(list(small_flights_df.ORIGIN_AIRPORT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dept_delay_by_airport = small_flights_df.groupby(['ORIGIN_AIRPORT'])['DEPARTURE_DELAY'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dept_by_airport = small_flights_df.groupby(['ORIGIN_AIRPORT'])['DEPARTURE_DELAY'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGIN_AIRPORT\n",
       "10135    10.075221\n",
       "10136     3.368132\n",
       "10140     5.682484\n",
       "10141     1.803030\n",
       "10146     9.500000\n",
       "Name: DEPARTURE_DELAY, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_delay_by_airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGIN_AIRPORT\n",
       "10135     226\n",
       "10136     182\n",
       "10140    1707\n",
       "10141      66\n",
       "10146      82\n",
       "Name: DEPARTURE_DELAY, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_by_airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = dept_by_airport.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = {k:{} for k in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    data_dict[key]['delay_mean'] = dept_delay_by_airport[key]\n",
    "    data_dict[key]['departures'] = dept_by_airport[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3d40dff7a2f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'departures'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delay_mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_dict' is not defined"
     ]
    }
   ],
   "source": [
    "x = [data_dict[k]['departures'] for k in data_dict]\n",
    "y = [data_dict[k]['delay_mean'] for k in data_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-56dca645369e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "plot(x,y,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log10\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x109d3f910>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTJWwgG+MMVXCAr4xxlQJC/jGGFMl/j969L9/aab5+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12282c850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = log10([data_dict[k]['departures'] for k in data_dict])\n",
    "y = [data_dict[k]['delay_mean'] for k in data_dict]\n",
    "\n",
    "plot(x,y,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cdcddf62ddb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/seaborn/regression.pyc\u001b[0m in \u001b[0;36mregplot\u001b[0;34m(x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, label, color, marker, scatter_kws, line_kws, ax)\u001b[0m\n\u001b[1;32m    780\u001b[0m                                  \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                                  \u001b[0mx_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                                  x_jitter, y_jitter, color, label)\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/seaborn/regression.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, color, label)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Drop null observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"units\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x_partial\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_partial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Regress nuisance variables out of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/seaborn/regression.pyc\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, *vars)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_na\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "sns.regplot(x, y, fit_reg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b892450b556b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'linear_model' is not defined"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c6fe91de3acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lm.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yarray = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-16554785a55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lm.fit(x, yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ufunc object:\n",
      "\n",
      "isnan = class ufunc(__builtin__.object)\n",
      " |  Functions that operate element by element on whole arrays.\n",
      " |  \n",
      " |  To see the documentation for a specific ufunc, use `info`.  For\n",
      " |  example, ``np.info(np.sin)``.  Because ufuncs are written in C\n",
      " |  (for speed) and linked into Python with NumPy's ufunc facility,\n",
      " |  Python's help() function finds this page whenever help() is called\n",
      " |  on a ufunc.\n",
      " |  \n",
      " |  A detailed explanation of ufuncs can be found in the docs for :ref:`ufuncs`.\n",
      " |  \n",
      " |  Calling ufuncs:\n",
      " |  ===============\n",
      " |  \n",
      " |  op(*x[, out], where=True, **kwargs)\n",
      " |  Apply `op` to the arguments `*x` elementwise, broadcasting the arguments.\n",
      " |  \n",
      " |  The broadcasting rules are:\n",
      " |  \n",
      " |  * Dimensions of length 1 may be prepended to either array.\n",
      " |  * Arrays may be repeated along dimensions of length 1.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  *x : array_like\n",
      " |      Input arrays.\n",
      " |  out : ndarray, None, or tuple of ndarray and None, optional\n",
      " |      Alternate array object(s) in which to put the result; if provided, it\n",
      " |      must have a shape that the inputs broadcast to. A tuple of arrays\n",
      " |      (possible only as a keyword argument) must have length equal to the\n",
      " |      number of outputs; use `None` for outputs to be allocated by the ufunc.\n",
      " |  where : array_like, optional\n",
      " |      Values of True indicate to calculate the ufunc at that position, values\n",
      " |      of False indicate to leave the value in the output alone.\n",
      " |  **kwargs\n",
      " |      For other keyword-only arguments, see the :ref:`ufunc docs <ufuncs.kwargs>`.\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  r : ndarray or tuple of ndarray\n",
      " |      `r` will have the shape that the arrays in `x` broadcast to; if `out` is\n",
      " |      provided, `r` will be equal to `out`. If the function has more than one\n",
      " |      output, then the result will be a tuple of arrays.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(...)\n",
      " |      x.__call__(...) <==> x(...)\n",
      " |  \n",
      " |  __repr__(...)\n",
      " |      x.__repr__() <==> repr(x)\n",
      " |  \n",
      " |  __str__(...)\n",
      " |      x.__str__() <==> str(x)\n",
      " |  \n",
      " |  accumulate(...)\n",
      " |      accumulate(array, axis=0, dtype=None, out=None, keepdims=None)\n",
      " |      \n",
      " |      Accumulate the result of applying the operator to all elements.\n",
      " |      \n",
      " |      For a one-dimensional array, accumulate produces results equivalent to::\n",
      " |      \n",
      " |        r = np.empty(len(A))\n",
      " |        t = op.identity        # op = the ufunc being applied to A's  elements\n",
      " |        for i in range(len(A)):\n",
      " |            t = op(t, A[i])\n",
      " |            r[i] = t\n",
      " |        return r\n",
      " |      \n",
      " |      For example, add.accumulate() is equivalent to np.cumsum().\n",
      " |      \n",
      " |      For a multi-dimensional array, accumulate is applied along only one\n",
      " |      axis (axis zero by default; see Examples below) so repeated use is\n",
      " |      necessary if one wants to accumulate over multiple axes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      array : array_like\n",
      " |          The array to act on.\n",
      " |      axis : int, optional\n",
      " |          The axis along which to apply the accumulation; default is zero.\n",
      " |      dtype : data-type code, optional\n",
      " |          The data-type used to represent the intermediate results. Defaults\n",
      " |          to the data-type of the output array if such is provided, or the\n",
      " |          the data-type of the input array if no output array is provided.\n",
      " |      out : ndarray, None, or tuple of ndarray and None, optional\n",
      " |          A location into which the result is stored. If not provided or `None`,\n",
      " |          a freshly-allocated array is returned. For consistency with\n",
      " |          :ref:`ufunc.__call__`, if given as a keyword, this may be wrapped in a\n",
      " |          1-element tuple.\n",
      " |      \n",
      " |          .. versionchanged:: 1.13.0\n",
      " |             Tuples are allowed for keyword argument.\n",
      " |      keepdims : bool\n",
      " |          Has no effect. Deprecated, and will be removed in future.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      r : ndarray\n",
      " |          The accumulated values. If `out` was supplied, `r` is a reference to\n",
      " |          `out`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      1-D array examples:\n",
      " |      \n",
      " |      >>> np.add.accumulate([2, 3, 5])\n",
      " |      array([ 2,  5, 10])\n",
      " |      >>> np.multiply.accumulate([2, 3, 5])\n",
      " |      array([ 2,  6, 30])\n",
      " |      \n",
      " |      2-D array examples:\n",
      " |      \n",
      " |      >>> I = np.eye(2)\n",
      " |      >>> I\n",
      " |      array([[ 1.,  0.],\n",
      " |             [ 0.,  1.]])\n",
      " |      \n",
      " |      Accumulate along axis 0 (rows), down columns:\n",
      " |      \n",
      " |      >>> np.add.accumulate(I, 0)\n",
      " |      array([[ 1.,  0.],\n",
      " |             [ 1.,  1.]])\n",
      " |      >>> np.add.accumulate(I) # no axis specified = axis zero\n",
      " |      array([[ 1.,  0.],\n",
      " |             [ 1.,  1.]])\n",
      " |      \n",
      " |      Accumulate along axis 1 (columns), through rows:\n",
      " |      \n",
      " |      >>> np.add.accumulate(I, 1)\n",
      " |      array([[ 1.,  1.],\n",
      " |             [ 0.,  1.]])\n",
      " |  \n",
      " |  at(...)\n",
      " |      at(a, indices, b=None)\n",
      " |      \n",
      " |      Performs unbuffered in place operation on operand 'a' for elements\n",
      " |      specified by 'indices'. For addition ufunc, this method is equivalent to\n",
      " |      `a[indices] += b`, except that results are accumulated for elements that\n",
      " |      are indexed more than once. For example, `a[[0,0]] += 1` will only\n",
      " |      increment the first element once because of buffering, whereas\n",
      " |      `add.at(a, [0,0], 1)` will increment the first element twice.\n",
      " |      \n",
      " |      .. versionadded:: 1.8.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : array_like\n",
      " |          The array to perform in place operation on.\n",
      " |      indices : array_like or tuple\n",
      " |          Array like index object or slice object for indexing into first\n",
      " |          operand. If first operand has multiple dimensions, indices can be a\n",
      " |          tuple of array like index objects or slice objects.\n",
      " |      b : array_like\n",
      " |          Second operand for ufuncs requiring two operands. Operand must be\n",
      " |          broadcastable over first operand after indexing or slicing.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Set items 0 and 1 to their negative values:\n",
      " |      \n",
      " |      >>> a = np.array([1, 2, 3, 4])\n",
      " |      >>> np.negative.at(a, [0, 1])\n",
      " |      >>> print(a)\n",
      " |      array([-1, -2, 3, 4])\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |      Increment items 0 and 1, and increment item 2 twice:\n",
      " |      \n",
      " |      >>> a = np.array([1, 2, 3, 4])\n",
      " |      >>> np.add.at(a, [0, 1, 2, 2], 1)\n",
      " |      >>> print(a)\n",
      " |      array([2, 3, 5, 4])\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |      Add items 0 and 1 in first array to second array,\n",
      " |      and store results in first array:\n",
      " |      \n",
      " |      >>> a = np.array([1, 2, 3, 4])\n",
      " |      >>> b = np.array([1, 2])\n",
      " |      >>> np.add.at(a, [0, 1], b)\n",
      " |      >>> print(a)\n",
      " |      array([2, 4, 3, 4])\n",
      " |  \n",
      " |  outer(...)\n",
      " |      outer(A, B, **kwargs)\n",
      " |      \n",
      " |      Apply the ufunc `op` to all pairs (a, b) with a in `A` and b in `B`.\n",
      " |      \n",
      " |      Let ``M = A.ndim``, ``N = B.ndim``. Then the result, `C`, of\n",
      " |      ``op.outer(A, B)`` is an array of dimension M + N such that:\n",
      " |      \n",
      " |      .. math:: C[i_0, ..., i_{M-1}, j_0, ..., j_{N-1}] =\n",
      " |         op(A[i_0, ..., i_{M-1}], B[j_0, ..., j_{N-1}])\n",
      " |      \n",
      " |      For `A` and `B` one-dimensional, this is equivalent to::\n",
      " |      \n",
      " |        r = empty(len(A),len(B))\n",
      " |        for i in range(len(A)):\n",
      " |            for j in range(len(B)):\n",
      " |                r[i,j] = op(A[i], B[j]) # op = ufunc in question\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      A : array_like\n",
      " |          First array\n",
      " |      B : array_like\n",
      " |          Second array\n",
      " |      kwargs : any\n",
      " |          Arguments to pass on to the ufunc. Typically `dtype` or `out`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      r : ndarray\n",
      " |          Output array\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.outer\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.multiply.outer([1, 2, 3], [4, 5, 6])\n",
      " |      array([[ 4,  5,  6],\n",
      " |             [ 8, 10, 12],\n",
      " |             [12, 15, 18]])\n",
      " |      \n",
      " |      A multi-dimensional example:\n",
      " |      \n",
      " |      >>> A = np.array([[1, 2, 3], [4, 5, 6]])\n",
      " |      >>> A.shape\n",
      " |      (2, 3)\n",
      " |      >>> B = np.array([[1, 2, 3, 4]])\n",
      " |      >>> B.shape\n",
      " |      (1, 4)\n",
      " |      >>> C = np.multiply.outer(A, B)\n",
      " |      >>> C.shape; C\n",
      " |      (2, 3, 1, 4)\n",
      " |      array([[[[ 1,  2,  3,  4]],\n",
      " |              [[ 2,  4,  6,  8]],\n",
      " |              [[ 3,  6,  9, 12]]],\n",
      " |             [[[ 4,  8, 12, 16]],\n",
      " |              [[ 5, 10, 15, 20]],\n",
      " |              [[ 6, 12, 18, 24]]]])\n",
      " |  \n",
      " |  reduce(...)\n",
      " |      reduce(a, axis=0, dtype=None, out=None, keepdims=False)\n",
      " |      \n",
      " |      Reduces `a`'s dimension by one, by applying ufunc along one axis.\n",
      " |      \n",
      " |      Let :math:`a.shape = (N_0, ..., N_i, ..., N_{M-1})`.  Then\n",
      " |      :math:`ufunc.reduce(a, axis=i)[k_0, ..,k_{i-1}, k_{i+1}, .., k_{M-1}]` =\n",
      " |      the result of iterating `j` over :math:`range(N_i)`, cumulatively applying\n",
      " |      ufunc to each :math:`a[k_0, ..,k_{i-1}, j, k_{i+1}, .., k_{M-1}]`.\n",
      " |      For a one-dimensional array, reduce produces results equivalent to:\n",
      " |      ::\n",
      " |      \n",
      " |       r = op.identity # op = ufunc\n",
      " |       for i in range(len(A)):\n",
      " |         r = op(r, A[i])\n",
      " |       return r\n",
      " |      \n",
      " |      For example, add.reduce() is equivalent to sum().\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : array_like\n",
      " |          The array to act on.\n",
      " |      axis : None or int or tuple of ints, optional\n",
      " |          Axis or axes along which a reduction is performed.\n",
      " |          The default (`axis` = 0) is perform a reduction over the first\n",
      " |          dimension of the input array. `axis` may be negative, in\n",
      " |          which case it counts from the last to the first axis.\n",
      " |      \n",
      " |          .. versionadded:: 1.7.0\n",
      " |      \n",
      " |          If this is `None`, a reduction is performed over all the axes.\n",
      " |          If this is a tuple of ints, a reduction is performed on multiple\n",
      " |          axes, instead of a single axis or all the axes as before.\n",
      " |      \n",
      " |          For operations which are either not commutative or not associative,\n",
      " |          doing a reduction over multiple axes is not well-defined. The\n",
      " |          ufuncs do not currently raise an exception in this case, but will\n",
      " |          likely do so in the future.\n",
      " |      dtype : data-type code, optional\n",
      " |          The type used to represent the intermediate results. Defaults\n",
      " |          to the data-type of the output array if this is provided, or\n",
      " |          the data-type of the input array if no output array is provided.\n",
      " |      out : ndarray, None, or tuple of ndarray and None, optional\n",
      " |          A location into which the result is stored. If not provided or `None`,\n",
      " |          a freshly-allocated array is returned. For consistency with\n",
      " |          :ref:`ufunc.__call__`, if given as a keyword, this may be wrapped in a\n",
      " |          1-element tuple.\n",
      " |      \n",
      " |          .. versionchanged:: 1.13.0\n",
      " |             Tuples are allowed for keyword argument.\n",
      " |      keepdims : bool, optional\n",
      " |          If this is set to True, the axes which are reduced are left\n",
      " |          in the result as dimensions with size one. With this option,\n",
      " |          the result will broadcast correctly against the original `arr`.\n",
      " |      \n",
      " |          .. versionadded:: 1.7.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      r : ndarray\n",
      " |          The reduced array. If `out` was supplied, `r` is a reference to it.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.multiply.reduce([2,3,5])\n",
      " |      30\n",
      " |      \n",
      " |      A multi-dimensional array example:\n",
      " |      \n",
      " |      >>> X = np.arange(8).reshape((2,2,2))\n",
      " |      >>> X\n",
      " |      array([[[0, 1],\n",
      " |              [2, 3]],\n",
      " |             [[4, 5],\n",
      " |              [6, 7]]])\n",
      " |      >>> np.add.reduce(X, 0)\n",
      " |      array([[ 4,  6],\n",
      " |             [ 8, 10]])\n",
      " |      >>> np.add.reduce(X) # confirm: default axis value is 0\n",
      " |      array([[ 4,  6],\n",
      " |             [ 8, 10]])\n",
      " |      >>> np.add.reduce(X, 1)\n",
      " |      array([[ 2,  4],\n",
      " |             [10, 12]])\n",
      " |      >>> np.add.reduce(X, 2)\n",
      " |      array([[ 1,  5],\n",
      " |             [ 9, 13]])\n",
      " |  \n",
      " |  reduceat(...)\n",
      " |      reduceat(a, indices, axis=0, dtype=None, out=None)\n",
      " |      \n",
      " |      Performs a (local) reduce with specified slices over a single axis.\n",
      " |      \n",
      " |      For i in ``range(len(indices))``, `reduceat` computes\n",
      " |      ``ufunc.reduce(a[indices[i]:indices[i+1]])``, which becomes the i-th\n",
      " |      generalized \"row\" parallel to `axis` in the final result (i.e., in a\n",
      " |      2-D array, for example, if `axis = 0`, it becomes the i-th row, but if\n",
      " |      `axis = 1`, it becomes the i-th column).  There are three exceptions to this:\n",
      " |      \n",
      " |      * when ``i = len(indices) - 1`` (so for the last index),\n",
      " |        ``indices[i+1] = a.shape[axis]``.\n",
      " |      * if ``indices[i] >= indices[i + 1]``, the i-th generalized \"row\" is\n",
      " |        simply ``a[indices[i]]``.\n",
      " |      * if ``indices[i] >= len(a)`` or ``indices[i] < 0``, an error is raised.\n",
      " |      \n",
      " |      The shape of the output depends on the size of `indices`, and may be\n",
      " |      larger than `a` (this happens if ``len(indices) > a.shape[axis]``).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : array_like\n",
      " |          The array to act on.\n",
      " |      indices : array_like\n",
      " |          Paired indices, comma separated (not colon), specifying slices to\n",
      " |          reduce.\n",
      " |      axis : int, optional\n",
      " |          The axis along which to apply the reduceat.\n",
      " |      dtype : data-type code, optional\n",
      " |          The type used to represent the intermediate results. Defaults\n",
      " |          to the data type of the output array if this is provided, or\n",
      " |          the data type of the input array if no output array is provided.\n",
      " |      out : ndarray, None, or tuple of ndarray and None, optional\n",
      " |          A location into which the result is stored. If not provided or `None`,\n",
      " |          a freshly-allocated array is returned. For consistency with\n",
      " |          :ref:`ufunc.__call__`, if given as a keyword, this may be wrapped in a\n",
      " |          1-element tuple.\n",
      " |      \n",
      " |          .. versionchanged:: 1.13.0\n",
      " |             Tuples are allowed for keyword argument.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      r : ndarray\n",
      " |          The reduced values. If `out` was supplied, `r` is a reference to\n",
      " |          `out`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      A descriptive example:\n",
      " |      \n",
      " |      If `a` is 1-D, the function `ufunc.accumulate(a)` is the same as\n",
      " |      ``ufunc.reduceat(a, indices)[::2]`` where `indices` is\n",
      " |      ``range(len(array) - 1)`` with a zero placed\n",
      " |      in every other element:\n",
      " |      ``indices = zeros(2 * len(a) - 1)``, ``indices[1::2] = range(1, len(a))``.\n",
      " |      \n",
      " |      Don't be fooled by this attribute's name: `reduceat(a)` is not\n",
      " |      necessarily smaller than `a`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      To take the running sum of four successive values:\n",
      " |      \n",
      " |      >>> np.add.reduceat(np.arange(8),[0,4, 1,5, 2,6, 3,7])[::2]\n",
      " |      array([ 6, 10, 14, 18])\n",
      " |      \n",
      " |      A 2-D example:\n",
      " |      \n",
      " |      >>> x = np.linspace(0, 15, 16).reshape(4,4)\n",
      " |      >>> x\n",
      " |      array([[  0.,   1.,   2.,   3.],\n",
      " |             [  4.,   5.,   6.,   7.],\n",
      " |             [  8.,   9.,  10.,  11.],\n",
      " |             [ 12.,  13.,  14.,  15.]])\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |       # reduce such that the result has the following five rows:\n",
      " |       # [row1 + row2 + row3]\n",
      " |       # [row4]\n",
      " |       # [row2]\n",
      " |       # [row3]\n",
      " |       # [row1 + row2 + row3 + row4]\n",
      " |      \n",
      " |      >>> np.add.reduceat(x, [0, 3, 1, 2, 0])\n",
      " |      array([[ 12.,  15.,  18.,  21.],\n",
      " |             [ 12.,  13.,  14.,  15.],\n",
      " |             [  4.,   5.,   6.,   7.],\n",
      " |             [  8.,   9.,  10.,  11.],\n",
      " |             [ 24.,  28.,  32.,  36.]])\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |       # reduce such that result has the following two columns:\n",
      " |       # [col1 * col2 * col3, col4]\n",
      " |      \n",
      " |      >>> np.multiply.reduceat(x, [0, 3], 1)\n",
      " |      array([[    0.,     3.],\n",
      " |             [  120.,     7.],\n",
      " |             [  720.,    11.],\n",
      " |             [ 2184.,    15.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  identity\n",
      " |      The identity value.\n",
      " |      \n",
      " |      Data attribute containing the identity element for the ufunc, if it has one.\n",
      " |      If it does not, the attribute value is None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.add.identity\n",
      " |      0\n",
      " |      >>> np.multiply.identity\n",
      " |      1\n",
      " |      >>> np.power.identity\n",
      " |      1\n",
      " |      >>> print(np.exp.identity)\n",
      " |      None\n",
      " |  \n",
      " |  nargs\n",
      " |      The number of arguments.\n",
      " |      \n",
      " |      Data attribute containing the number of arguments the ufunc takes, including\n",
      " |      optional ones.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Typically this value will be one more than what you might expect because all\n",
      " |      ufuncs take  the optional \"out\" argument.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.add.nargs\n",
      " |      3\n",
      " |      >>> np.multiply.nargs\n",
      " |      3\n",
      " |      >>> np.power.nargs\n",
      " |      3\n",
      " |      >>> np.exp.nargs\n",
      " |      2\n",
      " |  \n",
      " |  nin\n",
      " |      The number of inputs.\n",
      " |      \n",
      " |      Data attribute containing the number of arguments the ufunc treats as input.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.add.nin\n",
      " |      2\n",
      " |      >>> np.multiply.nin\n",
      " |      2\n",
      " |      >>> np.power.nin\n",
      " |      2\n",
      " |      >>> np.exp.nin\n",
      " |      1\n",
      " |  \n",
      " |  nout\n",
      " |      The number of outputs.\n",
      " |      \n",
      " |      Data attribute containing the number of arguments the ufunc treats as output.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Since all ufuncs can take output arguments, this will always be (at least) 1.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.add.nout\n",
      " |      1\n",
      " |      >>> np.multiply.nout\n",
      " |      1\n",
      " |      >>> np.power.nout\n",
      " |      1\n",
      " |      >>> np.exp.nout\n",
      " |      1\n",
      " |  \n",
      " |  ntypes\n",
      " |      The number of types.\n",
      " |      \n",
      " |      The number of numerical NumPy types - of which there are 18 total - on which\n",
      " |      the ufunc can operate.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ufunc.types\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.add.ntypes\n",
      " |      18\n",
      " |      >>> np.multiply.ntypes\n",
      " |      18\n",
      " |      >>> np.power.ntypes\n",
      " |      17\n",
      " |      >>> np.exp.ntypes\n",
      " |      7\n",
      " |      >>> np.remainder.ntypes\n",
      " |      14\n",
      " |  \n",
      " |  signature\n",
      " |  \n",
      " |  types\n",
      " |      Returns a list with types grouped input->output.\n",
      " |      \n",
      " |      Data attribute listing the data-type \"Domain-Range\" groupings the ufunc can\n",
      " |      deliver. The data-types are given using the character codes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ufunc.ntypes\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.add.types\n",
      " |      ['??->?', 'bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l',\n",
      " |      'LL->L', 'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'FF->F', 'DD->D',\n",
      " |      'GG->G', 'OO->O']\n",
      " |      \n",
      " |      >>> np.multiply.types\n",
      " |      ['??->?', 'bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l',\n",
      " |      'LL->L', 'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'FF->F', 'DD->D',\n",
      " |      'GG->G', 'OO->O']\n",
      " |      \n",
      " |      >>> np.power.types\n",
      " |      ['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l', 'LL->L',\n",
      " |      'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'FF->F', 'DD->D', 'GG->G',\n",
      " |      'OO->O']\n",
      " |      \n",
      " |      >>> np.exp.types\n",
      " |      ['f->f', 'd->d', 'g->g', 'F->F', 'D->D', 'G->G', 'O->O']\n",
      " |      \n",
      " |      >>> np.remainder.types\n",
      " |      ['bb->b', 'BB->B', 'hh->h', 'HH->H', 'ii->i', 'II->I', 'll->l', 'LL->L',\n",
      " |      'qq->q', 'QQ->Q', 'ff->f', 'dd->d', 'gg->g', 'OO->O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.isnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xnan = np.isnan(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1), dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(xnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[()]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(tuple, np.where(xnan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x[~numpy.isnan(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yarray = yarray[~numpy.isnan(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False], dtype=bool)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-16554785a55e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lm.fit(x, yarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x[numpy.isfinite(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xwithoutnan = x[~numpy.isnan(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ywithoutnan = yarray[~numpy.isnan(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 929]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e0d9d70ee2b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxwithoutnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mywithoutnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 929]"
     ]
    }
   ],
   "source": [
    "lm.fit(xwithoutnan, ywithoutnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(xwithoutnan.reshape(len(xwithoutnan),1), ywithoutnan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d8ae720f787b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intercept'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coefficient'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_outcome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm' is not defined"
     ]
    }
   ],
   "source": [
    "predict_outcome = lm.predict(10)\n",
    "predictions = {}\n",
    "predictions['intercept'] = lm.intercept_\n",
    "predictions['coefficient'] = lm.coef_\n",
    "predictions['predicted_value'] = predict_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 1.50001000104\n",
      "Coefficients [ 1.47691164]\n",
      "Predicted Value [ 5.93074492]\n"
     ]
    }
   ],
   "source": [
    "print \"Intercept\", predictions['intercept']\n",
    "print \"Coefficients\" , predictions['coefficient']\n",
    "print \"Predicted Value\" , predictions['predicted_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111528390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line = plt.scatter(xwithoutnan, ywithoutnan, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAr4xxlSI/w8YRyuBP5g5VQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117478d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slope , intercept = np.polyfit(xwithoutnan , ywithoutnan ,1)\n",
    "plt.plot(xwithoutnan, ywithoutnan, '.')\n",
    "l = plt.plot(xwithoutnan, slope*xwithoutnan + intercept, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.88649073,  2.54900326,  3.12515583,  0.77815125,  4.07364505,\n",
       "         2.86805636,  1.462398  ,  1.34242268,  2.83884909,  1.79239169,\n",
       "         3.26810973,  2.92272546,  1.32221929,  0.47712125,  1.73239376,\n",
       "         2.30535137,  3.19975518,  1.2787536 ,  2.4578819 ,  3.07003787,\n",
       "         1.5797836 ,  1.72427587,  0.30103   ,  3.18298497,  0.69897   ,\n",
       "         3.34927753,  1.69019608,  4.92737036,  3.06182931,  3.09447113,\n",
       "         2.81491318,  1.20411998,  2.76566855,  3.37032801,  2.41329976,\n",
       "         3.32448823,  1.68124124,  1.        ,  1.81291336,  3.25599573,\n",
       "         2.31806333,  3.60734778,  2.53655844,  0.        ,  2.67486114,\n",
       "         3.42651126,  5.28462246,  4.67105245,  3.86213138,  2.34242268,\n",
       "         3.09307131,  1.97772361,  2.7466342 ,  5.12154343,  2.67577834,\n",
       "         3.4937368 ,  1.74036269,  3.30189772,  4.37416156,  3.86593267,\n",
       "         0.77815125,  2.52113808,  1.11394335,  2.79379038,  1.39794001,\n",
       "         1.04139269,  1.76342799,  2.17318627,  3.45117216,  4.48855072,\n",
       "         2.94448267,  2.75358306,  2.78746047,  3.20411998,  2.39445168,\n",
       "         1.68124124,  0.30103   ,  1.17609126,  4.61812135,  2.94743372,\n",
       "         3.77070477,  0.47712125,  3.44466923,  3.57645653,  1.90848502,\n",
       "         3.19005142,  2.80550086,  3.8920946 ,  2.42160393,  0.30103   ,\n",
       "         2.02938378,  4.02440356,  2.80482068,  1.73239376,  3.95994722,\n",
       "         0.69897   ,  3.9106244 ,  2.85064624,  1.11394335,  2.86510397,\n",
       "         1.23044892,  3.58883173,  1.74036269,  1.43136376,  0.69897   ,\n",
       "         2.05307844,  1.85125835,  3.63958609,  3.03140846,  2.49276039,\n",
       "         1.5563025 ,  2.3283796 ,  2.84010609,  0.47712125,  4.20011146,\n",
       "         1.30103   ,  4.40027889,  1.92427929,  0.60205999,  0.60205999,\n",
       "         2.01283722,  4.34682223,  0.69897   ,  1.79934055,  4.9945415 ,\n",
       "         3.55230311,  4.5660248 ,  1.99122608,  1.11394335,  3.20844136,\n",
       "         2.75815462,  0.84509804,  3.55278985,  0.95424251,  2.24054925,\n",
       "         3.21722066,  1.54406804,  3.30254737,  2.78887512,  2.32428246,\n",
       "         2.11394335,  1.89762709,  3.48600519,  0.60205999,  4.89744564,\n",
       "         3.50799072,  2.23552845,  0.77815125,  2.31175386,  5.36858066,\n",
       "         1.88081359,  1.462398  ,  1.76342799,  1.92427929,  3.46134843,\n",
       "         1.39794001,  3.76611528,  2.30103   ,  3.39111161,  2.79588002,\n",
       "         2.15533604,  2.72509452,  3.48685536,  3.03382569,  2.59328607,\n",
       "         1.2787536 ,  2.36361198,  0.69897   ,  1.04139269,  2.40312052,\n",
       "         3.1886473 ,  1.51851394,  0.69897   ,  1.86923172,  0.60205999,\n",
       "         1.76342799,  1.75587486,  5.44365094,  2.39445168,  2.50920252,\n",
       "         1.76342799,  4.04450056,  2.8998205 ,  0.95424251,  3.77829599,\n",
       "         0.60205999,  2.82216808,  2.95327634,  2.21484385,  2.39093511,\n",
       "         0.        ,  3.98900462,  2.85125835,  1.49136169,  1.60205999,\n",
       "         1.07918125,  1.79239169,  3.24870874,  2.94448267,  4.12408016,\n",
       "         3.70415052,  4.52878819,  2.35218252,  4.25051759,  2.6946052 ,\n",
       "         3.62551823,  0.47712125,  2.87040391,  4.66585293,  3.3494718 ,\n",
       "         2.28103337,  2.29446623,  1.69897   ,  3.63356944,  4.27843348,\n",
       "         1.14612804,  3.3300077 ,  1.04139269,  2.26007139,  2.95664858,\n",
       "         1.17609126,  3.03901732,  2.97127585,  2.7126497 ,  3.98063957,\n",
       "         4.09124477,  3.67851838,  1.90848502,  1.50514998,  1.90848502,\n",
       "         1.93951925,  3.51600623,  3.74694541,  1.69897   ,  3.29622629,\n",
       "         2.13672057,  3.24054925,  3.18326984,  4.96347143,  1.86923172,\n",
       "         3.66651798,  2.07554696,  4.83633678,  4.0214374 ,  0.84509804,\n",
       "         2.23299611,  3.91724286,  2.37106786,  1.75587486,  1.71600334,\n",
       "         2.78675142,  0.47712125,  1.73239376,  2.51587384,  0.60205999,\n",
       "         4.84160971,  3.17260293,  0.47712125,  3.53198955,  3.22010809,\n",
       "         0.47712125,  3.65118106,  3.09551804,  2.38738983,  3.50785587,\n",
       "         0.77815125,  1.75587486,  3.5223138 ,  3.86946641,  2.7458552 ,\n",
       "         0.95424251,  2.54777471,  3.62920566,  2.96425963,  3.87817698,\n",
       "         2.86033801,  0.47712125,  1.39794001,  1.96378783,  2.08990511,\n",
       "         0.60205999,  3.48230177,  4.06397101,  2.32428246,  3.29092456,\n",
       "         1.69019608,  4.07631269,  2.05307844,  4.2214664 ,  3.53895056,\n",
       "         2.61066016,  2.49831055,  2.02938378,  2.15228834,  0.60205999,\n",
       "         1.462398  ,  2.05307844,  5.16421005,  2.26007139,  2.59439255,\n",
       "         0.        ,  2.93951925,  4.46938014,  2.66181269,  1.79239169,\n",
       "         3.34262004,  3.83231727,  3.65465775,  2.83695674,  2.4578819 ,\n",
       "         1.39794001,  2.74272513,  4.03318241,  2.60745502,  3.90401188,\n",
       "         2.86332286,  3.3494718 ,  3.61647551,  2.24054925,  1.69897   ,\n",
       "         3.73751069,  3.60884682,  1.41497335,  3.42045086,  1.76342799,\n",
       "         2.33243846,  1.80617997,  2.04532298,  2.91539984,  1.14612804,\n",
       "         2.77158748,  1.47712125,  2.99166901,  1.74818803,  2.99387691,\n",
       "         1.88649073,  3.77466292,  1.73239376,  3.02571538,  3.2219356 ,\n",
       "         0.84509804,  2.80345712,  0.90308999,  1.75587486,  2.98855896,\n",
       "         1.51851394,  2.59549622,  2.43775056,  3.84559409,  2.54900326,\n",
       "         0.84509804,  1.        ,  2.34830486,  1.53147892,  2.85612444,\n",
       "         3.05461305,  2.77959649,  2.70070372,  1.85125835,  3.85545858,\n",
       "         0.60205999,  2.31806333,  2.27415785,  1.88081359,  5.53704297,\n",
       "         0.60205999,  3.44232296,  2.1931246 ,  3.40019249,  2.9380191 ,\n",
       "         1.07918125,  1.54406804,  3.48043815,  0.77815125,  2.31597035,\n",
       "         0.47712125,  3.95491755,  1.04139269,  3.5171959 ,  1.        ,\n",
       "         1.17609126,  3.31513032,  2.29003461,  1.17609126,  3.34281731,\n",
       "         1.74818803,  0.95424251,  3.29047981,  1.69897   ,  1.04139269,\n",
       "         4.52989212,  1.20411998,  3.61794343,  1.41497335,  2.9609462 ,\n",
       "         2.78461729,  1.07918125,  3.24575936,  4.99697112,  1.462398  ,\n",
       "         3.49858621,  1.38021124,  3.75671216,  4.21766815,  2.2764618 ,\n",
       "         2.75739603,  2.75050839,  2.06069784,  2.673942  ,  2.30103   ,\n",
       "         2.11394335,  4.13839744,  1.79934055,  2.94645227,  0.47712125,\n",
       "         3.8080083 ,  1.75587486,  2.1271048 ,  2.53275438,  1.95424251,\n",
       "         2.33041377,  2.79518459,  1.07918125,  3.52569252,  2.8344207 ,\n",
       "         2.42324587,  3.92675391,  2.95951838,  2.2764618 ,  0.60205999,\n",
       "         1.38021124,  2.0211893 ,  3.4557582 ,  1.        ,  1.99563519,\n",
       "         5.03065234,  0.77815125,  2.43136376,  1.34242268,  3.85576137,\n",
       "         1.17609126,  3.57054294,  1.8920946 ,  4.81295344,  3.15715444,\n",
       "         3.53083978,  5.16034846,  1.91907809,  1.63346846,  3.09447113,\n",
       "         2.13672057,  1.2787536 ,  2.6580114 ,  3.6836773 ,  3.5602654 ,\n",
       "         1.04139269,  2.35410844,  1.36172784,  3.19089172,  3.46089784,\n",
       "         3.13513265,  2.18184359,  2.46389299,  4.98613998,  5.0410135 ,\n",
       "         2.2787536 ,  4.58241566,  2.85003326,  3.94036705,  2.14921911,\n",
       "         4.9786552 ,  2.73479983,  2.85369821,  0.        ,  0.60205999,\n",
       "         2.04921802,  3.7455432 ,  3.74562122,  2.41664051,  2.85064624,\n",
       "         2.81756537,  2.02530587,  3.8067225 ,  1.91907809,  1.97312785,\n",
       "         3.80590846,  2.96707973,  3.08778142,  2.55990663,  2.29885308,\n",
       "         1.61278386,  2.73158877,  0.77815125,  4.23322463,  1.91907809,\n",
       "         3.39585038,  1.2787536 ,  1.76342799,  4.29007915,  0.69897   ,\n",
       "         2.90794852,  0.90308999,  1.88649073,  2.04532298,  2.81157501,\n",
       "         4.8565416 ,  2.04139269,  1.75587486,  2.76937733,  2.47275645,\n",
       "         2.4578819 ,  0.60205999,  4.17452498,  1.        ,  2.41497335,\n",
       "         0.60205999,  2.32221929,  2.49415459,  3.53857373,  2.74272513,\n",
       "         2.14612804,  3.04960561,  1.20411998,  3.54777471,  4.66793834,\n",
       "         0.69897   ,  1.11394335,  4.00710738,  1.07918125,  1.47712125,\n",
       "         4.06295783,  3.09272064,  2.61172331,  4.15959727,  5.16432311,\n",
       "         4.80141743,  3.8409212 ,  2.32014629,  0.77815125,  2.22010809,\n",
       "         0.        ,  0.47712125,  3.67577834,  4.17533783,  3.36679638,\n",
       "         2.26245109,  1.11394335,  0.90308999,  1.39794001,  2.23044892,\n",
       "         1.20411998,  2.42160393,  0.77815125,  2.82085799,  2.34044411,\n",
       "         3.51890857,  4.2689522 ,  3.97322025,  2.90036713,  2.20951501,\n",
       "         4.00052084,  3.3872118 ,  3.97602884,  3.08098705,  1.66275783,\n",
       "         4.21790487,  0.69897   ,  2.8142476 ,  3.19534606,  0.95424251,\n",
       "         1.76342799,  3.41027096,  0.60205999,  1.50514998,  2.54654266,\n",
       "         3.78838052,  4.31202918,  3.31344537,  4.11001701,  1.04139269,\n",
       "         4.20150637,  3.38111508,  1.32221929,  0.47712125,  1.47712125,\n",
       "         1.34242268,  1.91907809,  2.99869516,  3.67504474,  3.94890176,\n",
       "         2.80345712,  3.25671775,  3.94733568,  2.68033551,  3.83052451,\n",
       "         0.        ,  3.09656244,  1.69897   ,  2.5865873 ,  2.67577834,\n",
       "         3.26576092,  3.28216878,  3.16016829,  2.26481782,  3.42894429,\n",
       "         2.99122608,  2.81491318,  2.90687353,  2.68304704,  1.59106461,\n",
       "         1.68124124,  3.8205955 ,  0.47712125,  2.34044411,  1.73239376,\n",
       "         1.64345268,  2.78675142,  0.47712125,  1.69019608,  1.07918125,\n",
       "         0.60205999,  2.49136169,  1.23044892,  2.37474835,  0.95424251,\n",
       "         5.04677602,  2.57634135,  1.49136169,  1.        ,  1.71600334,\n",
       "         3.95371138,  1.2787536 ,  0.47712125,  2.14921911,  1.63346846,\n",
       "         0.47712125,  1.92941893,  2.75204845,  2.21748394,  2.05690485,\n",
       "         2.82151353,  2.81491318,  0.        ,  1.59106461,  2.6946052 ,\n",
       "         2.78816837,  2.14921911,  3.81197694,  1.462398  ,  1.04139269,\n",
       "         2.06069784,  1.91381385,  4.46639305,  0.77815125,  2.77597433,\n",
       "         2.33645973,  4.26580802,  2.8162413 ,  0.84509804,  2.74741181,\n",
       "         4.29105789,  3.26126287,  1.07918125,  3.45362407,  2.81491318,\n",
       "         0.69897   ,  3.20897852,  2.02938378,  4.25132181,  1.8920946 ,\n",
       "         3.15411953,  2.48429984,  3.05880549,  3.84229713,  2.17318627,\n",
       "         3.733839  ,  3.33745926,  1.32221929,  0.60205999,  0.84509804,\n",
       "         3.218798  ,  2.30103   ,  0.47712125,  2.5865873 ,  0.60205999,\n",
       "         0.60205999,  2.68841982,  2.79795964,  3.30362798,  0.95424251,\n",
       "         3.69258256,  3.41463915,  1.51851394,  0.84509804,  1.74818803,\n",
       "         2.02530587,  3.5774918 ,  0.95424251,  2.50379068,  2.82736927,\n",
       "         0.84509804,  1.17609126,  3.99926107,  2.73319727,  3.65753389,\n",
       "         1.        ,  2.62013605,  2.71349054,  2.21748394,  2.75739603,\n",
       "         1.88081359,  3.22942585,  1.98677173,  0.60205999,  5.02232938,\n",
       "         4.62068769,  3.70748501,  0.47712125,  1.74818803,  3.30621051,\n",
       "         3.71458121,  3.18892848,  1.67209786,  1.11394335,  1.17609126,\n",
       "         2.57518784,  2.75281643,  3.67531998,  3.1519824 ,  1.73239376,\n",
       "         4.3755173 ,  3.21404868,  3.12450422,  2.94051648,  4.63363002,\n",
       "         0.69897   ,  3.25863728,  1.91907809,  1.74818803,  1.5563025 ,\n",
       "         2.7930916 ,  4.41637419,  2.93500315,  2.8920946 ,  1.74818803,\n",
       "         3.36002509,  1.        ,  2.79098848,  1.76342799,  1.80617997,\n",
       "         1.93449845,  1.41497335,  1.74818803,  1.93449845,  0.47712125,\n",
       "         3.49720618,  1.50514998,  0.60205999,  2.40993312,  1.75587486,\n",
       "         0.60205999,  4.86241763,  5.28797407,  4.5666378 ,  3.20709554,\n",
       "         2.97266559,  0.47712125,  3.61129836,  2.87679498,  3.86141492,\n",
       "         2.57863921,  0.60205999,  1.34242268,  2.34439227,  1.74818803,\n",
       "         2.73878056,  0.90308999,  2.96378783,  3.28080593,  1.11394335,\n",
       "         1.07918125,  2.45331834,  2.66464198,  3.21245396,  1.72427587,\n",
       "         2.06818586,  2.53147892,  2.94200805,  1.25527251,  2.0374265 ,\n",
       "         2.74896286,  2.77524626,  1.11394335,  2.25527251,  2.0211893 ,\n",
       "         0.60205999,  1.91907809,  3.63154523,  3.42275394,  3.12417806,\n",
       "         0.47712125,  1.43136376,  2.63948649,  1.11394335,  1.17609126,\n",
       "         2.80753503,  0.        ,  0.90308999,  2.68663627,  2.93851973,\n",
       "         3.95409772,  2.02938378,  3.75777549,  3.10380372,  0.69897   ,\n",
       "         1.04139269,  3.54802069,  4.08564729,  2.65224634,  1.69019608,\n",
       "         1.63346846,  3.34830486,  1.73239376,  3.70139527,  3.30341207,\n",
       "         0.        ,  1.11394335,  0.47712125,  3.89817648,  1.30103   ,\n",
       "         4.49395967,  2.42324587,  1.76342799,  2.64048144,  0.77815125,\n",
       "         1.51851394,  4.38870496,  0.60205999,  0.84509804,  1.11394335,\n",
       "         3.32715451,  4.57719298,  2.22530928,  1.94939001,  0.77815125,\n",
       "         1.8920946 ,  2.91803034,  2.95182304,  3.35506821,  2.65127801,\n",
       "         0.60205999,  1.83884909,  3.7646244 ,  2.70070372,  2.76492298,\n",
       "         2.12385164,  3.64708943,  0.95424251,  0.90308999,  4.58437646,\n",
       "         3.24204424,  2.76937733,  1.66275783,  0.77815125,  3.54715912,\n",
       "         0.90308999,  3.00173371,  2.16435286,  1.69897   ,  2.15836249,\n",
       "         0.60205999,  2.35410844,  2.26007139,  3.23223352,  1.81954394,\n",
       "         3.64816478,  1.91381385,  2.96378783,  2.83122969,  3.17318627,\n",
       "         2.36361198,  4.76993092,  1.44715803,  2.13353891,  2.29446623,\n",
       "         2.04139269,  2.42488164,  1.74818803,  0.90308999,  5.04326794,\n",
       "         0.95424251,  2.79657433,  1.41497335,  0.95424251,  2.56702637,\n",
       "         1.41497335,  2.80345712,  3.92386548,  3.78326023,  2.73878056,\n",
       "         0.30103   ,  2.42324587,  2.65321251,  0.60205999,  2.31175386,\n",
       "         3.24204424,  4.7100327 ,  2.74507479,  2.4456042 ,  0.60205999,\n",
       "         0.47712125,  1.69897   ,  2.3283796 ,  3.01199311,  3.12287092,\n",
       "         0.60205999,  3.45009508,  1.32221929,  4.09352674,  1.04139269,\n",
       "         1.88649073,  2.65321251,  3.52283531,  2.81491318,  3.34693946,\n",
       "         2.2787536 ,  1.17609126,  0.60205999,  4.43187818]),\n",
       " array([ 4.28619011,  5.26466259,  6.11558903,  2.64927064,  7.51642379,\n",
       "         5.73587583,  3.65984263,  3.48264969,  5.69273927,  4.14721415,\n",
       "         6.3267193 ,  5.81661725,  3.45281107,  2.20467594,  4.05860251,\n",
       "         4.90481027,  6.22576567,  3.38861608,  5.13008439,  6.03418466,\n",
       "         3.83321078,  4.0466131 ,  1.94460471,  6.20099755,  2.53232694,\n",
       "         6.44659697,  3.99628027,  8.77730065,  6.02206135,  6.07027043,\n",
       "         5.65738805,  3.27838882,  5.58465808,  6.47768667,  5.06424052,\n",
       "         6.40998537,  3.98305476,  2.97692164,  4.17752284,  6.30882799,\n",
       "         4.92358472,  6.82774392,  5.24628269,  1.50001   ,  5.45054356,\n",
       "         6.56066437,  9.30493043,  8.39874173,  7.20403679,  4.95956133,\n",
       "         6.06820302,  4.42093302,  5.55654602,  9.06407711,  5.45189818,\n",
       "         6.65995055,  4.07037192,  6.37662118,  7.96026013,  7.20965096,\n",
       "         2.64927064,  5.22350818,  3.14520591,  5.62619154,  3.56464387,\n",
       "         3.03805498,  4.10443733,  4.7096141 ,  6.59708633,  8.1292028 ,\n",
       "         5.84875074,  5.56680887,  5.61684282,  6.2322121 ,  5.03640356,\n",
       "         3.98305476,  1.94460471,  3.23699287,  8.32056717,  5.85310918,\n",
       "         7.06900777,  2.20467594,  6.58748209,  6.78212029,  4.31867374,\n",
       "         6.21143407,  5.64348688,  7.24828983,  5.07650503,  1.94460471,\n",
       "         4.49723053,  7.44369847,  5.64248231,  4.05860251,  7.34850214,\n",
       "         2.53232694,  7.27565671,  5.71016261,  3.14520591,  5.73151541,\n",
       "         3.31727434,  6.80039735,  4.07037192,  3.61400781,  2.53232694,\n",
       "         4.53222545,  4.23415501,  6.87535706,  5.97713245,  5.18159684,\n",
       "         3.79853128,  4.93882094,  5.69459575,  2.20467594,  7.70320351,\n",
       "         3.42151635,  7.99883312,  4.34200048,  2.38919941,  2.38919941,\n",
       "         4.47279273,  7.91988235,  2.53232694,  4.157477  ,  8.87650649,\n",
       "         6.74644781,  8.24362519,  4.44087497,  3.14520591,  6.23859439,\n",
       "         5.57356067,  2.74814513,  6.74716669,  2.90934187,  4.80910327,\n",
       "         6.25156064,  3.78046207,  6.37758066,  5.61893212,  4.93276982,\n",
       "         4.62211755,  4.30263754,  6.64853164,  2.38919941,  8.73310448,\n",
       "         6.68100234,  4.80168799,  2.64927064,  4.91426619,  9.42892926,\n",
       "         4.27780549,  3.65984263,  4.10443733,  4.34200048,  6.6121158 ,\n",
       "         3.56464387,  7.0622295 ,  4.89842799,  6.50838222,  5.62927774,\n",
       "         4.68325088,  5.52473382,  6.64978726,  5.98070248,  5.33006438,\n",
       "         3.38861608,  4.99085605,  2.53232694,  3.03805498,  5.04920667,\n",
       "         6.20936031,  3.74272092,  2.53232694,  4.26070009,  2.38919941,\n",
       "         4.10443733,  4.09328202,  9.53980144,  5.03640356,  5.20588042,\n",
       "         4.10443733,  7.47337996,  5.78278866,  2.90934187,  7.08021933,\n",
       "         2.38919941,  5.66810289,  5.8617382 ,  4.77113866,  5.03120989,\n",
       "         1.50001   ,  7.39141735,  5.71106665,  3.70261945,  3.86611105,\n",
       "         3.09386535,  4.14721415,  6.29806575,  5.84875074,  7.59091199,\n",
       "         6.97071302,  8.18863   ,  4.97397574,  7.7776489 ,  5.47970379,\n",
       "         6.85458008,  2.20467594,  5.73934294,  8.3910625 ,  6.44688389,\n",
       "         4.86889473,  4.88873388,  4.00923858,  6.86647101,  7.81887821,\n",
       "         3.19273984,  6.41813714,  3.03805498,  4.83793574,  5.86671871,\n",
       "         3.23699287,  5.98837006,  5.88832189,  5.50635392,  7.37906292,\n",
       "         7.54241702,  6.93285662,  4.31867374,  3.72298353,  4.31867374,\n",
       "         4.36450856,  6.69284053,  7.03391729,  4.00923858,  6.36824498,\n",
       "         4.65575748,  6.28601491,  6.20141829,  8.83061874,  4.26070009,\n",
       "         6.91513309,  4.56540947,  8.64285209,  7.4393177 ,  2.74814513,\n",
       "         4.79794795,  7.28543158,  5.00186773,  4.09328202,  4.03439531,\n",
       "         5.61579562,  2.20467594,  4.05860251,  5.21573337,  2.38919941,\n",
       "         8.65063975,  6.1856642 ,  2.20467594,  6.71644648,  6.25582512,\n",
       "         2.20467594,  6.89248181,  6.07181663,  5.02597383,  6.68080317,\n",
       "         2.64927064,  4.09328202,  6.70215625,  7.21486999,  5.5553955 ,\n",
       "         2.90934187,  5.26284812,  6.86002608,  5.87795956,  7.22773473,\n",
       "         5.7244765 ,  2.20467594,  3.56464387,  4.4003511 ,  4.58661519,\n",
       "         2.38919941,  6.64306202,  7.50213609,  4.93276982,  6.36041479,\n",
       "         3.99628027,  7.52036366,  4.53222545,  7.73474287,  6.72672728,\n",
       "         5.35572439,  5.18979394,  4.49723053,  4.67874971,  2.38919941,\n",
       "         3.65984263,  4.53222545,  9.12709194,  4.83793574,  5.33169856,\n",
       "         1.50001   ,  5.8414202 ,  8.10088955,  5.43127214,  4.14721415,\n",
       "         6.43676445,  7.16000399,  6.89761658,  5.68994443,  5.13008439,\n",
       "         3.56464387,  5.55077267,  7.45666406,  5.35099068,  7.2658906 ,\n",
       "         5.72888486,  6.44688389,  6.84122479,  4.80910327,  4.00923858,\n",
       "         7.01998305,  6.82995788,  3.58980061,  6.55171369,  4.10443733,\n",
       "         4.94481551,  4.16757823,  4.52077132,  5.80579796,  3.19273984,\n",
       "         5.59339982,  3.68158758,  5.91844078,  4.08192925,  5.92170167,\n",
       "         4.28619011,  7.07485361,  4.05860251,  5.96872427,  6.25852419,\n",
       "         2.74814513,  5.64046845,  2.83379412,  4.09328202,  5.91384751,\n",
       "         3.74272092,  5.33332858,  5.10035218,  7.17961268,  5.26466259,\n",
       "         2.74814513,  2.97692164,  4.96824879,  3.76186904,  5.71825344,\n",
       "         6.01140358,  5.60522842,  5.48871076,  4.23415501,  7.19418166,\n",
       "         2.38919941,  4.92358472,  4.8587402 ,  4.27780549,  9.67773321,\n",
       "         2.38919941,  6.58401685,  4.73906125,  6.52179387,  5.83920461,\n",
       "         3.09386535,  3.78046207,  6.64030962,  2.64927064,  4.92049356,\n",
       "         2.20467594,  7.34107377,  3.03805498,  6.69459757,  2.97692164,\n",
       "         3.23699287,  6.39616456,  4.88218878,  3.23699287,  6.43705581,\n",
       "         4.08192925,  2.90934187,  6.35975794,  4.00923858,  3.03805498,\n",
       "         8.19026041,  3.27838882,  6.84339278,  3.58980061,  5.87306591,\n",
       "         5.6126437 ,  3.09386535,  6.29370978,  8.88009481,  3.65984263,\n",
       "         6.6671127 ,  3.53846005,  7.04834192,  7.72913319,  4.86214294,\n",
       "         5.57244029,  5.56226787,  4.54347863,  5.44918607,  4.89842799,\n",
       "         4.62211755,  7.61205736,  4.157477  ,  5.85165965,  2.20467594,\n",
       "         7.12410179,  4.09328202,  4.64155584,  5.24066443,  4.38625351,\n",
       "         4.94182523,  5.62825066,  3.09386535,  6.70714633,  5.68619893,\n",
       "         5.07893004,  7.29947855,  5.87095714,  4.86214294,  2.38919941,\n",
       "         3.53846005,  4.48512801,  6.60385952,  2.97692164,  4.44738685,\n",
       "         8.929839  ,  2.64927064,  5.09091945,  3.48264969,  7.19462886,\n",
       "         3.23699287,  6.77338643,  4.29446655,  8.60831697,  6.16284815,\n",
       "         6.71474837,  9.12138871,  4.33431878,  3.91249858,  6.07027043,\n",
       "         4.65575748,  3.38861608,  5.42565797,  6.94047588,  6.75820741,\n",
       "         3.03805498,  4.97682016,  3.51116169,  6.21267512,  6.61145031,\n",
       "         6.13032391,  4.72240019,  5.13896224,  8.86409818,  8.94514152,\n",
       "         4.86552772,  8.26783303,  5.7092573 ,  7.31958396,  4.67421673,\n",
       "         8.85304381,  5.5390677 ,  5.71467011,  1.50001   ,  2.38919941,\n",
       "         4.52652395,  7.03184636,  7.03196158,  5.0691745 ,  5.71016261,\n",
       "         5.66130509,  4.49120781,  7.12220278,  4.33431878,  4.4141455 ,\n",
       "         7.1210005 ,  5.8821246 ,  6.06039032,  5.28076589,  4.89521287,\n",
       "         3.88194925,  5.53432525,  2.64927064,  7.75210873,  4.33431878,\n",
       "         6.51538095,  3.38861608,  4.10443733,  7.83607784,  2.53232694,\n",
       "         5.79479302,  2.83379412,  4.28619011,  4.52077132,  5.65245786,\n",
       "         8.67269283,  4.51496662,  4.09328202,  5.59013561,  5.15205279,\n",
       "         5.13008439,  2.38919941,  7.66541454,  2.97692164,  5.06671225,\n",
       "         2.38919941,  4.92972271,  5.18365595,  6.72617074,  5.55077267,\n",
       "         4.66965148,  6.00400803,  3.27838882,  6.73975976,  8.39414248,\n",
       "         2.53232694,  3.14520591,  7.41815354,  3.09386535,  3.68158758,\n",
       "         7.50063972,  6.06768512,  5.35729456,  7.64336763,  9.12725892,\n",
       "         8.5912793 ,  7.17271123,  4.92666106,  2.64927064,  4.77891348,\n",
       "         1.50001   ,  2.20467594,  6.92880982,  7.66661504,  6.47247077,\n",
       "         4.84145035,  3.14520591,  2.83379412,  3.56464387,  4.79418598,\n",
       "         3.27838882,  5.07650503,  2.64927064,  5.666168  ,  4.95663916,\n",
       "         6.69712704,  7.8048752 ,  7.36810524,  5.78359598,  4.76326845,\n",
       "         7.4084258 ,  6.50262254,  7.37225328,  6.05035564,  3.9557564 ,\n",
       "         7.72948281,  2.53232694,  5.65640504,  6.21925379,  2.90934187,\n",
       "         4.10443733,  6.53667889,  2.38919941,  3.72298353,  5.2610285 ,\n",
       "         7.09511328,  7.86849609,  6.39367604,  7.57014196,  3.03805498,\n",
       "         7.70526366,  6.49361822,  3.45281107,  2.20467594,  3.68158758,\n",
       "         3.48264969,  4.33431878,  5.92881779,  6.92772635,  7.33218898,\n",
       "         5.64046845,  6.30989435,  7.32987601,  5.45862872,  7.15735625,\n",
       "         1.50001   ,  6.07335911,  4.00923858,  5.3201709 ,  5.45189818,\n",
       "         6.32325031,  6.34748328,  6.16729934,  4.84494581,  6.56425774,\n",
       "         5.91778661,  5.65738805,  5.79320536,  5.4626334 ,  3.84987184,\n",
       "         3.98305476,  7.14269196,  2.20467594,  4.95663916,  4.05860251,\n",
       "         3.92724439,  5.61579562,  2.20467594,  3.99628027,  3.09386535,\n",
       "         2.38919941,  5.17953109,  3.31727434,  5.00730348,  2.90934187,\n",
       "         8.95365225,  5.30503853,  3.70261945,  2.97692164,  4.03439531,\n",
       "         7.33929236,  3.38861608,  2.20467594,  4.67421673,  3.91249858,\n",
       "         2.20467594,  4.34959127,  5.56454239,  4.77503785,  4.53787672,\n",
       "         5.66713618,  5.65738805,  1.50001   ,  3.84987184,  5.47970379,\n",
       "         5.61788832,  4.67421673,  7.12996312,  3.65984263,  3.03805498,\n",
       "         4.54347863,  4.32654396,  8.09647788,  2.64927064,  5.59987881,\n",
       "         4.95075458,  7.80023152,  5.65934956,  2.74814513,  5.55769448,\n",
       "         7.83752336,  6.3166071 ,  3.09386535,  6.6007076 ,  5.65738805,\n",
       "         2.53232694,  6.23938773,  4.49723053,  7.77883667,  4.29446655,\n",
       "         6.15836584,  5.16910135,  6.01759543,  7.17474337,  4.7096141 ,\n",
       "         7.01456029,  6.42914243,  3.45281107,  2.38919941,  2.74814513,\n",
       "         6.25389023,  4.89842799,  2.20467594,  5.3201709 ,  2.38919941,\n",
       "         2.38919941,  5.47056853,  5.63234917,  6.37917662,  2.90934187,\n",
       "         6.95362817,  6.54313031,  3.74272092,  2.74814513,  4.08192925,\n",
       "         4.49120781,  6.78364929,  2.90934187,  5.19788761,  5.67578459,\n",
       "         2.74814513,  3.23699287,  7.40656523,  5.53670086,  6.90186438,\n",
       "         2.97692164,  5.36971944,  5.50759577,  4.77503785,  5.57244029,\n",
       "         4.27780549,  6.26958663,  4.4342963 ,  2.38919941,  8.91754672,\n",
       "         8.32435743,  6.97563777,  2.20467594,  4.08192925,  6.38299079,\n",
       "         6.98611823,  6.2097756 ,  3.96955079,  3.14520591,  3.23699287,\n",
       "         5.30333491,  5.56567663,  6.92813287,  6.15520949,  4.05860251,\n",
       "         7.96226244,  6.24687591,  6.11462666,  5.84289303,  8.34347212,\n",
       "         2.53232694,  6.31272934,  4.33431878,  4.08192925,  3.79853128,\n",
       "         5.6251595 ,  8.02260445,  5.83475032,  5.77137819,  4.08192925,\n",
       "         6.46247017,  2.97692164,  5.62205337,  4.10443733,  4.16757823,\n",
       "         4.35709328,  3.58980061,  4.08192925,  4.35709328,  2.20467594,\n",
       "         6.66507452,  3.72298353,  2.38919941,  5.05926828,  4.09328202,\n",
       "         2.38919941,  8.68137121,  9.30988046,  8.24453053,  6.23660674,\n",
       "         5.89037442,  2.20467594,  6.83357859,  5.74878199,  7.20297864,\n",
       "         5.30843227,  2.38919941,  3.48264969,  4.96247024,  4.08192925,\n",
       "         5.54494689,  2.83379412,  5.87726274,  6.34547047,  3.14520591,\n",
       "         3.09386535,  5.12334442,  5.43545075,  6.24452065,  4.0466131 ,\n",
       "         4.55453778,  5.23878068,  5.84509594,  3.35393658,  4.50910891,\n",
       "         5.55998525,  5.59880351,  3.14520591,  4.83084822,  4.48512801,\n",
       "         2.38919941,  4.33431878,  6.86348142,  6.55511514,  6.11414494,\n",
       "         2.20467594,  3.61400781,  5.39829832,  3.14520591,  3.23699287,\n",
       "         5.64649117,  1.50001   ,  2.83379412,  5.46793438,  5.83994399,\n",
       "         7.33986295,  4.49723053,  7.04991237,  6.08405385,  2.53232694,\n",
       "         3.03805498,  6.74012307,  7.53415004,  5.4171435 ,  3.99628027,\n",
       "         3.91249858,  6.44516043,  4.05860251,  6.96664376,  6.37885774,\n",
       "         1.50001   ,  3.14520591,  2.20467594,  7.25727223,  3.42151635,\n",
       "         8.13719136,  5.07893004,  4.10443733,  5.39976777,  2.64927064,\n",
       "         3.74272092,  7.98173944,  2.38919941,  2.74814513,  3.14520591,\n",
       "         6.41392323,  8.26011959,  4.78659518,  4.37908679,  2.64927064,\n",
       "         4.29446655,  5.80968297,  5.8595918 ,  6.45514929,  5.41571336,\n",
       "         2.38919941,  4.21582763,  7.0600276 ,  5.48871076,  5.58355694,\n",
       "         4.63675121,  6.88643883,  2.90934187,  2.83379412,  8.27072896,\n",
       "         6.28822288,  5.59013561,  3.9557564 ,  2.64927064,  6.7388506 ,\n",
       "         2.83379412,  5.93330546,  4.69656793,  4.00923858,  4.68772069,\n",
       "         2.38919941,  4.97682016,  4.83793574,  6.27373331,  4.18731562,\n",
       "         6.88802703,  4.32654396,  5.87726274,  5.68148609,  6.18652574,\n",
       "         4.99085605,  8.5447765 ,  3.63733454,  4.65105845,  4.88873388,\n",
       "         4.51496662,  5.08134592,  4.08192925,  2.83379412,  8.94847113,\n",
       "         2.90934187,  5.63030319,  3.58980061,  2.90934187,  5.29128112,\n",
       "         3.58980061,  5.64046845,  7.2952126 ,  7.08755108,  5.54494689,\n",
       "         1.94460471,  5.07893004,  5.41857045,  2.38919941,  4.91426619,\n",
       "         6.28822288,  8.45631212,  5.55424292,  5.11195132,  2.38919941,\n",
       "         2.20467594,  4.00923858,  4.93882094,  5.94845769,  6.11221442,\n",
       "         2.38919941,  6.59549558,  3.45281107,  7.5457873 ,  3.03805498,\n",
       "         4.28619011,  5.41857045,  6.70292648,  5.65738805,  6.44314385,\n",
       "         4.86552772,  3.23699287,  2.38919941,  8.04550247]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matplotlib.collections.PathCollection"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linearray = np.array(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(linearray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-6108c329dd97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlinearray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "linearray[0].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-128-daa8a440c0c0>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-128-daa8a440c0c0>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    plt.show()\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "plt.plot(xwithoutnan.reshape(len(xwithoutnan,1),lm.predict(xwithoutnan), color='orange',linewidth='4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1ef51f13ba75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "help(np.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
